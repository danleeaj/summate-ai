## SERVER ADDRESS ------------------------------------------------------
# This is the URL of the LM Studio local server to which the API 
# calls will be made.

SERVER_URL = "http://127.0.0.1:1234/v1/chat/completions"

## MODEL
# This is the model LM Studio will use to perform inference.
# Ensure that this model is downloaded in LM Studio first before 
# using it.

MODEL = "meta-llama-3.1-8b-instruct"